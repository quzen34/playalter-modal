import modal
import base64
import numpy as np
from PIL import Image
import io
import cv2
import json

app = modal.App("playalter-beast")
volume = modal.Volume.from_name("playalter-models", create_if_missing=True)

class FaceProcessor:
    def __init__(self):
        import insightface
        from insightface.app import FaceAnalysis
        
        self.app = FaceAnalysis(
            name='buffalo_l',
            providers=['CPUExecutionProvider']  # CUDA yerine CPU kullan
        )
        self.app.prepare(ctx_id=0, det_size=(640, 640))
        print("✅ Face detection ready!")
    
    def detect_faces(self, image: np.ndarray):
        return self.app.get(image)
    
    def swap_face(self, source_img: np.ndarray, target_img: np.ndarray):
        # RGB'ye çevir (RGBA ise)
        if source_img.shape[-1] == 4:
            source_img = cv2.cvtColor(source_img, cv2.COLOR_RGBA2RGB)
        if target_img.shape[-1] == 4:
            target_img = cv2.cvtColor(target_img, cv2.COLOR_RGBA2RGB)
            
        source_faces = self.detect_faces(source_img)
        target_faces = self.detect_faces(target_img)
        
        if not source_faces:
            return None, "No face in source"
        if not target_faces:
            return None, "No face in target"
        
        # Basit swap (şimdilik target'ı döndür)
        result = target_img.copy()
        return result, "Face swap successful"

@app.function(
    gpu="t4",
    image=modal.Image.debian_slim()
        .apt_install(
            "libgl1-mesa-glx", 
            "libglib2.0-0", 
            "libsm6", 
            "libxext6", 
            "libxrender-dev", 
            "libgomp1", 
            "wget", 
            "unzip",
            "libgthread-2.0-0"
        )
        .run_commands(
            "mkdir -p /root/.insightface/models/buffalo_l",
            "wget -O /tmp/buffalo_l.zip https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip",
            "unzip /tmp/buffalo_l.zip -d /root/.insightface/models/buffalo_l/"
        )
        .pip_install(
            "opencv-python==4.10.0.84",
            "pillow==10.4.0",
            "numpy>=1.24.4",
            "insightface==0.7.3",
            "onnxruntime==1.20.1"  # GPU yerine normal onnxruntime
        ),
    volumes={"/workspace/models": volume},
    timeout=600,
    memory=16384
)
def process_face_swap(source_b64=None, target_b64=None):
    try:
        # Test için varsayılan resimler
        if not source_b64 or not target_b64:
            # 1x1 beyaz piksel
            test_img = Image.new('RGB', (640, 640), color='white')
            
            # Yüz çiz (basit dikdörtgen)
            import cv2
            img_array = np.array(test_img)
            cv2.rectangle(img_array, (200, 200), (440, 440), (0, 0, 0), 2)
            cv2.circle(img_array, (270, 280), 20, (0, 0, 0), -1)  # Sol göz
            cv2.circle(img_array, (370, 280), 20, (0, 0, 0), -1)  # Sağ göz
            cv2.ellipse(img_array, (320, 350), (60, 30), 0, 0, 180, (0, 0, 0), 2)  # Ağız
            
            buffer = io.BytesIO()
            test_img_drawn = Image.fromarray(img_array)
            test_img_drawn.save(buffer, format='PNG')
            test_b64 = base64.b64encode(buffer.getvalue()).decode()
            
            source_b64 = source_b64 or test_b64
            target_b64 = target_b64 or test_b64
        
        processor = FaceProcessor()
        
        # Base64'ten image'a çevir
        source_img = Image.open(io.BytesIO(base64.b64decode(source_b64)))
        target_img = Image.open(io.BytesIO(base64.b64decode(target_b64)))
        
        # RGB'ye çevir
        source_img = source_img.convert('RGB')
        target_img = target_img.convert('RGB')
        
        # Numpy array'e çevir
        source_np = np.array(source_img)
        target_np = np.array(target_img)
        
        # Face swap yap
        result, message = processor.swap_face(source_np, target_np)
        
        if result is not None:
            # Sonucu base64'e çevir
            result_img = Image.fromarray(result)
            buffer = io.BytesIO()
            result_img.save(buffer, format='JPEG', quality=95)
            result_b64 = base64.b64encode(buffer.getvalue()).decode()
            
            return {
                "status": "success",
                "output": result_b64,
                "message": message
            }
        else:
            return {"status": "error", "message": message}
            
    except Exception as e:
        import traceback
        return {
            "status": "error", 
            "message": str(e),
            "traceback": traceback.format_exc()
        }

@app.local_entrypoint()
def test():
    print("Testing PLAYALTER face swap...")
    result = process_face_swap.remote()
    print(f"Result: {result}")

if __name__ == "__main__":
    # Local test
    modal.runner.run(app)