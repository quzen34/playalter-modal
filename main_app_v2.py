import modal
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from PIL import Image, ImageDraw, ImageFilter, ImageEnhance
import io
import base64
import numpy as np
from typing import Optional, List, Dict, Any
import cv2
import tempfile
import os
import json
import asyncio
from concurrent.futures import ThreadPoolExecutor
import threading

# Create Modal app
app = modal.App("playalter-platform-v2")

# Advanced image with comprehensive face processing libraries
image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "fastapi",
    "pillow",
    "numpy",
    "opencv-python-headless",
    "python-multipart",
    "torch",
    "torchvision",
    "torchaudio",
    "facenet-pytorch",
    "mediapipe",
    "scikit-learn",
    "tensorflow",
    "onnxruntime",
    "insightface",
    "retinaface-pytorch",
    "dlib"
).run_commands(
    "apt-get update",
    "apt-get install -y cmake build-essential libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1"
)

web_app = FastAPI()

# Ethnicity classifications
ETHNICITIES = {
    "African": {
        "subgroups": ["West_African", "East_African", "Southern_African"],
        "features": {
            "skin_tone_range": [(0.2, 0.1, 0.05), (0.6, 0.4, 0.3)],
            "hair_texture": ["coily", "kinky", "tight_curly"],
            "bone_structure": "prominent_cheekbones"
        }
    },
    "Asian": {
        "subgroups": ["East_Asian", "Southeast_Asian", "South_Asian"],
        "features": {
            "skin_tone_range": [(0.7, 0.6, 0.4), (0.95, 0.85, 0.7)],
            "eye_shape": "monolid_variations",
            "facial_structure": "refined_angular"
        }
    },
    "Caucasian": {
        "subgroups": ["Nordic", "Mediterranean", "Slavic"],
        "features": {
            "skin_tone_range": [(0.8, 0.7, 0.6), (0.98, 0.95, 0.9)],
            "eye_shapes": "varied",
            "nose_structure": "varied_prominent"
        }
    },
    "Hispanic": {
        "subgroups": ["Mexican", "South_American", "Caribbean"],
        "features": {
            "skin_tone_range": [(0.5, 0.4, 0.3), (0.9, 0.8, 0.7)],
            "mixed_features": "indigenous_european_blend",
            "bone_structure": "varied_mixed"
        }
    },
    "Middle_Eastern": {
        "subgroups": ["Arab", "Persian", "Turkish"],
        "features": {
            "skin_tone_range": [(0.6, 0.5, 0.4), (0.85, 0.75, 0.65)],
            "facial_structure": "strong_defined",
            "hair_texture": ["straight", "wavy", "curly"]
        }
    }
}

# Mock advanced face detection (would use RetinaFace in production)
def advanced_face_detection(image: Image.Image) -> List[Dict[str, Any]]:
    """Advanced face detection with bounding boxes and landmarks"""
    # Convert PIL to numpy
    img_array = np.array(image)
    height, width = img_array.shape[:2]
    
    # Mock detection for demo - simulate multiple faces
    faces = []
    
    # Simulate detecting faces at different positions
    face_positions = [
        (0.2, 0.15, 0.35, 0.45),  # Face 1 - top left
        (0.6, 0.2, 0.35, 0.4),    # Face 2 - top right  
        (0.1, 0.55, 0.3, 0.35),   # Face 3 - bottom left
        (0.65, 0.6, 0.3, 0.35),   # Face 4 - bottom right
        (0.35, 0.35, 0.3, 0.3),   # Face 5 - center
    ]
    
    for i, (x, y, w, h) in enumerate(face_positions):
        # Convert relative to absolute coordinates
        abs_x = int(x * width)
        abs_y = int(y * height)
        abs_w = int(w * width)
        abs_h = int(h * height)
        
        # Check if face region is reasonable
        if abs_x + abs_w < width and abs_y + abs_h < height:
            # Extract face region
            face_region = img_array[abs_y:abs_y+abs_h, abs_x:abs_x+abs_w]
            
            if face_region.size > 0:
                face_pil = Image.fromarray(face_region)
                
                # Mock ethnicity detection
                ethnicity = mock_ethnicity_detection(face_pil)
                
                faces.append({
                    'id': f'face_{i+1}',
                    'bbox': [abs_x, abs_y, abs_w, abs_h],
                    'confidence': 0.95 - (i * 0.05),
                    'ethnicity': ethnicity,
                    'landmarks': generate_mock_landmarks(abs_x, abs_y, abs_w, abs_h),
                    'face_image': face_to_base64(face_pil)
                })
    
    return faces[:5]  # Return up to 5 faces for demo

def mock_ethnicity_detection(face_image: Image.Image) -> Dict[str, Any]:
    """Mock ethnicity detection - would use FairFace or similar in production"""
    # Analyze average color for mock classification
    img_array = np.array(face_image)
    avg_color = np.mean(img_array, axis=(0, 1))
    
    # Mock classification based on color analysis
    ethnicities = list(ETHNICITIES.keys())
    
    # Simple mock logic - in reality this would use trained models
    if avg_color[0] < 100:  # Darker skin tones
        ethnicity = "African"
        subgroup = "West_African"
        confidence = 0.85
    elif avg_color[0] > 200 and avg_color[1] > 180:  # Very light skin
        ethnicity = "Caucasian" 
        subgroup = "Nordic"
        confidence = 0.80
    elif avg_color[1] > avg_color[0] and avg_color[1] > avg_color[2]:  # Yellowish undertones
        ethnicity = "Asian"
        subgroup = "East_Asian"
        confidence = 0.82
    elif avg_color[0] > avg_color[2] and avg_color[1] > avg_color[2]:  # Olive/warm tones
        ethnicity = "Hispanic"
        subgroup = "Mexican"
        confidence = 0.78
    else:
        ethnicity = "Middle_Eastern"
        subgroup = "Arab" 
        confidence = 0.75
    
    return {
        'primary': ethnicity,
        'subgroup': subgroup,
        'confidence': confidence,
        'all_scores': {eth: np.random.random() * 0.3 for eth in ethnicities}
    }

def generate_mock_landmarks(x, y, w, h):
    """Generate mock facial landmarks"""
    # Basic 5-point landmarks: eyes, nose, mouth corners
    return {
        'left_eye': [x + w*0.3, y + h*0.35],
        'right_eye': [x + w*0.7, y + h*0.35],
        'nose': [x + w*0.5, y + h*0.55],
        'left_mouth': [x + w*0.35, y + h*0.75],
        'right_mouth': [x + w*0.65, y + h*0.75]
    }

def face_to_base64(face_image: Image.Image) -> str:
    """Convert face PIL image to base64 string"""
    buffered = io.BytesIO()
    face_image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def generate_ethnicity_specific_mask(face_image: Image.Image, ethnicity_data: Dict, mask_type: str) -> Image.Image:
    """Generate ethnicity-aware privacy mask"""
    img_copy = face_image.copy()
    width, height = img_copy.size
    ethnicity = ethnicity_data['primary']
    
    # Get ethnicity-specific features
    features = ETHNICITIES.get(ethnicity, ETHNICITIES['Caucasian'])['features']
    
    if mask_type == "blur":
        if ethnicity == "African":
            # Preserve skin tone while blurring
            blur_radius = 15
            img_copy = img_copy.filter(ImageFilter.GaussianBlur(radius=blur_radius))
            # Enhance to maintain skin tone richness
            enhancer = ImageEnhance.Color(img_copy)
            img_copy = enhancer.enhance(1.2)
            
        elif ethnicity == "Asian":
            # Softer blur to maintain delicate features
            blur_radius = 12
            img_copy = img_copy.filter(ImageFilter.GaussianBlur(radius=blur_radius))
            # Slight brightness adjustment
            enhancer = ImageEnhance.Brightness(img_copy)
            img_copy = enhancer.enhance(1.1)
            
        elif ethnicity == "Hispanic":
            # Medium blur with warmth preservation
            blur_radius = 14
            img_copy = img_copy.filter(ImageFilter.GaussianBlur(radius=blur_radius))
            enhancer = ImageEnhance.Color(img_copy)
            img_copy = enhancer.enhance(1.15)
            
        elif ethnicity == "Middle_Eastern":
            # Balanced blur with contrast preservation
            blur_radius = 13
            img_copy = img_copy.filter(ImageFilter.GaussianBlur(radius=blur_radius))
            enhancer = ImageEnhance.Contrast(img_copy)
            img_copy = enhancer.enhance(1.1)
            
        else:  # Caucasian or default
            blur_radius = 16
            img_copy = img_copy.filter(ImageFilter.GaussianBlur(radius=blur_radius))
    
    elif mask_type == "pixelate":
        # Ethnicity-aware pixelation sizes
        if ethnicity in ["African", "Hispanic"]:
            pixel_size = 15  # Larger pixels to preserve skin tone blocks
        elif ethnicity == "Asian":
            pixel_size = 12  # Medium pixels for feature preservation
        else:
            pixel_size = 18  # Standard pixelation
            
        # Apply pixelation
        small = img_copy.resize((width//pixel_size, height//pixel_size), Image.Resampling.NEAREST)
        img_copy = small.resize((width, height), Image.Resampling.NEAREST)
    
    elif mask_type == "stylized_mask":
        # Create ethnicity-appropriate stylized masks
        draw = ImageDraw.Draw(img_copy)
        
        if ethnicity == "African":
            # Geometric patterns inspired by African art
            for i in range(5):
                y_pos = height // 6 * (i + 1)
                draw.line([(0, y_pos), (width, y_pos)], fill=(139, 69, 19), width=3)
            
        elif ethnicity == "Asian":
            # Subtle geometric patterns
            center_x, center_y = width // 2, height // 2
            for i in range(3):
                radius = (i + 1) * min(width, height) // 8
                draw.ellipse([center_x - radius, center_y - radius, 
                            center_x + radius, center_y + radius], 
                           outline=(200, 180, 120), width=2)
        
        elif ethnicity == "Hispanic":
            # Warm color overlays
            overlay = Image.new('RGBA', (width, height), (255, 140, 0, 100))
            img_copy = Image.alpha_composite(img_copy.convert('RGBA'), overlay).convert('RGB')
            
        elif ethnicity == "Middle_Eastern":
            # Ornate pattern overlays
            draw.rectangle([width//4, height//4, 3*width//4, 3*height//4], 
                         outline=(150, 100, 50), width=3)
        
        else:  # Caucasian
            # Simple geometric overlay
            draw.rectangle([width//6, height//6, 5*width//6, 5*height//6], 
                         outline=(100, 100, 100), width=4)
    
    # Add ethnicity-specific watermark
    draw = ImageDraw.Draw(img_copy)
    watermark = f"PLAYALTER - {ethnicity} Aware"
    draw.text((5, height - 15), watermark, fill=(255, 255, 255, 180))
    
    return img_copy

@app.function(image=image)
def detect_faces(file_bytes: bytes, file_type: str) -> dict:
    """Detect all faces in uploaded media with ethnicity classification"""
    try:
        if file_type in ["image/jpeg", "image/png", "image/jpg"]:
            image = Image.open(io.BytesIO(file_bytes)).convert("RGB")
            
            # Perform advanced face detection
            faces = advanced_face_detection(image)
            
            return {
                "success": True,
                "total_faces": len(faces),
                "faces": faces,
                "image_dimensions": {"width": image.width, "height": image.height}
            }
        else:
            return {"success": False, "message": "Unsupported file type"}
            
    except Exception as e:
        return {"success": False, "message": f"Face detection error: {str(e)}"}

@app.function(image=image)
def process_individual_face(
    source_bytes: bytes,
    face_id: str,
    bbox: List[int],
    ethnicity_data: Dict,
    operation: str,
    target_bytes: Optional[bytes] = None
) -> dict:
    """Process individual face with ethnicity-aware algorithms"""
    try:
        source_image = Image.open(io.BytesIO(source_bytes)).convert("RGB")
        
        # Extract face region
        x, y, w, h = bbox
        face_region = source_image.crop((x, y, x + w, y + h))
        
        if operation == "face_swap" and target_bytes:
            target_image = Image.open(io.BytesIO(target_bytes)).convert("RGB")
            # Resize target to match face region
            target_resized = target_image.resize(face_region.size)
            
            # Ethnicity-aware face swap
            if ethnicity_data['primary'] == "African":
                # Preserve skin tone in blending
                processed_face = Image.blend(face_region, target_resized, alpha=0.4)
                enhancer = ImageEnhance.Color(processed_face)
                processed_face = enhancer.enhance(1.2)
            else:
                processed_face = Image.blend(face_region, target_resized, alpha=0.5)
                
        elif operation.startswith("privacy_"):
            mask_type = operation.replace("privacy_", "")
            processed_face = generate_ethnicity_specific_mask(face_region, ethnicity_data, mask_type)
            
        else:
            processed_face = face_region
        
        # Convert result to base64
        buffered = io.BytesIO()
        processed_face.save(buffered, format="PNG")
        result_base64 = base64.b64encode(buffered.getvalue()).decode()
        
        return {
            "success": True,
            "face_id": face_id,
            "processed_face": result_base64,
            "ethnicity": ethnicity_data,
            "operation": operation
        }
        
    except Exception as e:
        return {"success": False, "message": f"Face processing error: {str(e)}"}

@app.function(image=image)
def batch_process_faces(
    source_bytes: bytes,
    face_operations: List[Dict],
    target_files: Dict[str, bytes] = None
) -> dict:
    """Process multiple faces in parallel"""
    try:
        source_image = Image.open(io.BytesIO(source_bytes)).convert("RGB")
        results = []
        
        # Process each face operation
        for face_op in face_operations:
            face_id = face_op['face_id']
            target_bytes = target_files.get(face_id) if target_files else None
            
            result = process_individual_face.remote(
                source_bytes=source_bytes,
                face_id=face_id,
                bbox=face_op['bbox'],
                ethnicity_data=face_op['ethnicity'],
                operation=face_op['operation'],
                target_bytes=target_bytes
            )
            results.append(result)
        
        return {
            "success": True,
            "processed_faces": results,
            "total_processed": len(results)
        }
        
    except Exception as e:
        return {"success": False, "message": f"Batch processing error: {str(e)}"}

# Enhanced HTML template with multi-face interface
ADVANCED_HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PLAYALTER v2.0 - Advanced Multi-Face Platform</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            border-radius: 25px;
            padding: 40px;
            box-shadow: 0 25px 80px rgba(0, 0, 0, 0.3);
        }
        
        h1 {
            text-align: center;
            font-size: 3.5em;
            margin-bottom: 10px;
            background: linear-gradient(45deg, #fff, #f0f0f0);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-shadow: 2px 2px 8px rgba(0, 0, 0, 0.3);
        }
        
        .version-badge {
            text-align: center;
            font-size: 1em;
            margin-bottom: 30px;
            background: linear-gradient(45deg, #4ade80, #22c55e);
            padding: 8px 20px;
            border-radius: 20px;
            display: inline-block;
            font-weight: bold;
        }
        
        .upload-section {
            margin-bottom: 40px;
        }
        
        .main-upload {
            background: rgba(255, 255, 255, 0.15);
            border: 3px dashed rgba(255, 255, 255, 0.6);
            border-radius: 20px;
            padding: 50px;
            text-align: center;
            cursor: pointer;
            transition: all 0.4s ease;
            margin-bottom: 30px;
        }
        
        .main-upload:hover {
            background: rgba(255, 255, 255, 0.25);
            border-color: #4ade80;
            transform: translateY(-3px);
        }
        
        .main-upload input[type="file"] {
            display: none;
        }
        
        .upload-icon {
            font-size: 4em;
            margin-bottom: 20px;
        }
        
        .faces-grid {
            display: none;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 25px;
            margin-top: 30px;
        }
        
        .face-card {
            background: rgba(255, 255, 255, 0.12);
            border-radius: 20px;
            padding: 25px;
            border: 2px solid transparent;
            transition: all 0.3s ease;
        }
        
        .face-card.processing {
            border-color: #4ade80;
            background: rgba(74, 222, 128, 0.1);
        }
        
        .face-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
        }
        
        .face-id {
            font-size: 1.4em;
            font-weight: bold;
        }
        
        .ethnicity-badge {
            padding: 6px 15px;
            border-radius: 15px;
            font-size: 0.9em;
            font-weight: bold;
        }
        
        .ethnicity-African { background: #8B4513; }
        .ethnicity-Asian { background: #FF6B6B; }
        .ethnicity-Caucasian { background: #4ECDC4; }
        .ethnicity-Hispanic { background: #45B7D1; }
        .ethnicity-Middle_Eastern { background: #F7DC6F; color: #333; }
        
        .face-preview {
            width: 120px;
            height: 120px;
            border-radius: 15px;
            object-fit: cover;
            border: 3px solid rgba(255, 255, 255, 0.3);
            margin-bottom: 15px;
        }
        
        .face-operations {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }
        
        .swap-section {
            display: flex;
            align-items: center;
            gap: 15px;
            padding: 15px;
            background: rgba(255, 255, 255, 0.08);
            border-radius: 12px;
        }
        
        .target-upload {
            position: relative;
            width: 80px;
            height: 80px;
            border: 2px dashed rgba(255, 255, 255, 0.5);
            border-radius: 10px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }
        
        .target-upload:hover {
            border-color: #4ade80;
            background: rgba(74, 222, 128, 0.1);
        }
        
        .target-upload input[type="file"] {
            display: none;
        }
        
        .target-preview {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 8px;
        }
        
        .operation-buttons {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }
        
        .operation-btn {
            padding: 10px 15px;
            background: linear-gradient(45deg, #667eea, #764ba2);
            border: none;
            border-radius: 8px;
            color: white;
            cursor: pointer;
            font-size: 0.9em;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .operation-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }
        
        .batch-controls {
            display: none;
            margin: 30px 0;
            text-align: center;
            gap: 20px;
        }
        
        .batch-btn {
            padding: 15px 30px;
            background: linear-gradient(45deg, #4ade80, #22c55e);
            border: none;
            border-radius: 12px;
            color: white;
            font-size: 1.1em;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .batch-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(74, 222, 128, 0.4);
        }
        
        .results-section {
            display: none;
            margin-top: 40px;
        }
        
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
        }
        
        .result-card {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 15px;
            text-align: center;
        }
        
        .result-image {
            width: 100%;
            max-width: 200px;
            height: auto;
            border-radius: 10px;
            margin-bottom: 15px;
        }
        
        .loading-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 1000;
        }
        
        .loading-content {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
            color: white;
        }
        
        .spinner {
            width: 60px;
            height: 60px;
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #4ade80;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .detection-stats {
            display: none;
            background: rgba(74, 222, 128, 0.2);
            border: 1px solid #4ade80;
            padding: 20px;
            border-radius: 15px;
            margin: 20px 0;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            text-align: center;
        }
        
        .stat-item {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px;
            border-radius: 10px;
        }
        
        .stat-number {
            font-size: 2em;
            font-weight: bold;
            color: #4ade80;
        }
        
        @media (max-width: 768px) {
            .faces-grid {
                grid-template-columns: 1fr;
            }
            
            h1 {
                font-size: 2.5em;
            }
            
            .container {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé≠ PLAYALTER v2.0</h1>
        <div style="text-align: center;">
            <span class="version-badge">Advanced Multi-Face & Ethnicity-Aware Processing</span>
        </div>
        
        <div class="upload-section">
            <div class="main-upload" id="mainUpload">
                <input type="file" id="mainFile" accept="image/*,video/*">
                <div class="upload-icon">üöÄ</div>
                <div style="font-size: 1.5em; margin-bottom: 10px;">Upload Group Photo or Video</div>
                <div style="opacity: 0.8;">Supports up to 30 faces simultaneously</div>
            </div>
        </div>
        
        <div class="detection-stats" id="detectionStats">
            <h3 style="margin-bottom: 20px;">üîç Detection Results</h3>
            <div class="stats-grid">
                <div class="stat-item">
                    <div class="stat-number" id="totalFaces">0</div>
                    <div>Total Faces</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number" id="ethnicGroups">0</div>
                    <div>Ethnic Groups</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number" id="avgConfidence">0%</div>
                    <div>Avg Confidence</div>
                </div>
            </div>
        </div>
        
        <div class="faces-grid" id="facesGrid"></div>
        
        <div class="batch-controls" id="batchControls">
            <button class="batch-btn" onclick="processAllFaces()">üéØ Process All Faces</button>
            <button class="batch-btn" onclick="downloadResults()" style="background: linear-gradient(45deg, #764ba2, #667eea);">
                üíæ Download PSD Layers
            </button>
        </div>
        
        <div class="results-section" id="resultsSection">
            <h3>‚ú® Processing Results</h3>
            <div class="results-grid" id="resultsGrid"></div>
        </div>
    </div>
    
    <div class="loading-overlay" id="loadingOverlay">
        <div class="loading-content">
            <div class="spinner"></div>
            <div id="loadingText">Processing faces with AI...</div>
        </div>
    </div>
    
    <script>
        let detectedFaces = [];
        let sourceFile = null;
        let targetFiles = {};
        let processedResults = [];
        
        // Main upload handler
        document.getElementById('mainUpload').addEventListener('click', () => {
            document.getElementById('mainFile').click();
        });
        
        document.getElementById('mainFile').addEventListener('change', async (e) => {
            if (e.target.files.length > 0) {
                sourceFile = e.target.files[0];
                await detectFaces();
            }
        });
        
        async function detectFaces() {
            showLoading('Detecting faces and analyzing ethnicities...');
            
            const formData = new FormData();
            formData.append('file', sourceFile);
            
            try {
                const response = await fetch('/detect-faces', {
                    method: 'POST',
                    body: formData
                });
                
                const result = await response.json();
                hideLoading();
                
                if (result.success) {
                    detectedFaces = result.faces;
                    showDetectionResults(result);
                    renderFacesGrid();
                } else {
                    alert('Face detection failed: ' + result.message);
                }
                
            } catch (error) {
                hideLoading();
                alert('Error: ' + error.message);
            }
        }
        
        function showDetectionResults(result) {
            document.getElementById('totalFaces').textContent = result.total_faces;
            
            // Count unique ethnicities
            const ethnicities = new Set(result.faces.map(f => f.ethnicity.primary));
            document.getElementById('ethnicGroups').textContent = ethnicities.size;
            
            // Calculate average confidence
            const avgConf = result.faces.reduce((sum, f) => sum + f.ethnicity.confidence, 0) / result.faces.length;
            document.getElementById('avgConfidence').textContent = Math.round(avgConf * 100) + '%';
            
            document.getElementById('detectionStats').style.display = 'block';
        }
        
        function renderFacesGrid() {
            const grid = document.getElementById('facesGrid');
            grid.innerHTML = '';
            
            detectedFaces.forEach((face, index) => {
                const faceCard = createFaceCard(face, index);
                grid.appendChild(faceCard);
            });
            
            grid.style.display = 'grid';
            document.getElementById('batchControls').style.display = 'flex';
        }
        
        function createFaceCard(face, index) {
            const card = document.createElement('div');
            card.className = 'face-card';
            card.id = `face-card-${face.id}`;
            
            const ethnicity = face.ethnicity.primary;
            const confidence = Math.round(face.ethnicity.confidence * 100);
            
            card.innerHTML = `
                <div class="face-header">
                    <div class="face-id">Face ${index + 1}</div>
                    <div class="ethnicity-badge ethnicity-${ethnicity}">
                        ${ethnicity} (${confidence}%)
                    </div>
                </div>
                
                <div style="display: flex; gap: 20px; align-items: flex-start;">
                    <img src="data:image/png;base64,${face.face_image}" class="face-preview" alt="Face ${index + 1}">
                    
                    <div class="face-operations" style="flex: 1;">
                        <div class="swap-section">
                            <div>‚ÜîÔ∏è Face Swap:</div>
                            <div class="target-upload" onclick="selectTargetFile('${face.id}')">
                                <input type="file" id="target-${face.id}" accept="image/*" style="display: none;">
                                <div id="target-placeholder-${face.id}">+</div>
                                <img id="target-preview-${face.id}" class="target-preview" style="display: none;">
                            </div>
                            <button class="operation-btn" onclick="processFace('${face.id}', 'face_swap')">
                                Swap
                            </button>
                        </div>
                        
                        <div class="operation-buttons">
                            <button class="operation-btn" onclick="processFace('${face.id}', 'privacy_blur')">
                                üîê ${ethnicity} Blur
                            </button>
                            <button class="operation-btn" onclick="processFace('${face.id}', 'privacy_pixelate')">
                                üî≤ Pixelate
                            </button>
                            <button class="operation-btn" onclick="processFace('${face.id}', 'privacy_stylized_mask')">
                                üé® Stylized
                            </button>
                        </div>
                    </div>
                </div>
            `;
            
            return card;
        }
        
        function selectTargetFile(faceId) {
            document.getElementById(`target-${faceId}`).click();
            
            document.getElementById(`target-${faceId}`).onchange = function(e) {
                if (e.target.files.length > 0) {
                    targetFiles[faceId] = e.target.files[0];
                    
                    // Show preview
                    const reader = new FileReader();
                    reader.onload = function(e) {
                        document.getElementById(`target-placeholder-${faceId}`).style.display = 'none';
                        const preview = document.getElementById(`target-preview-${faceId}`);
                        preview.src = e.target.result;
                        preview.style.display = 'block';
                    };
                    reader.readAsDataURL(e.target.files[0]);
                }
            };
        }
        
        async function processFace(faceId, operation) {
            const face = detectedFaces.find(f => f.id === faceId);
            if (!face) return;
            
            // Mark card as processing
            document.getElementById(`face-card-${faceId}`).classList.add('processing');
            
            showLoading(`Processing ${face.ethnicity.primary} face with ${operation}...`);
            
            const formData = new FormData();
            formData.append('source_file', sourceFile);
            formData.append('face_id', faceId);
            formData.append('bbox', JSON.stringify(face.bbox));
            formData.append('ethnicity', JSON.stringify(face.ethnicity));
            formData.append('operation', operation);
            
            if (operation === 'face_swap' && targetFiles[faceId]) {
                formData.append('target_file', targetFiles[faceId]);
            }
            
            try {
                const response = await fetch('/process-face', {
                    method: 'POST',
                    body: formData
                });
                
                const result = await response.json();
                hideLoading();
                
                if (result.success) {
                    addProcessedResult(result);
                    showResults();
                } else {
                    alert('Processing failed: ' + result.message);
                }
                
            } catch (error) {
                hideLoading();
                alert('Error: ' + error.message);
            } finally {
                document.getElementById(`face-card-${faceId}`).classList.remove('processing');
            }
        }
        
        function addProcessedResult(result) {
            processedResults.push(result);
            
            const resultsGrid = document.getElementById('resultsGrid');
            const resultCard = document.createElement('div');
            resultCard.className = 'result-card';
            
            resultCard.innerHTML = `
                <img src="data:image/png;base64,${result.processed_face}" class="result-image" alt="Processed face">
                <div><strong>${result.face_id}</strong></div>
                <div>${result.ethnicity.primary} - ${result.operation}</div>
                <button onclick="downloadSingle('${result.face_id}')" style="margin-top: 10px; padding: 8px 15px; background: #4ade80; border: none; border-radius: 5px; color: white; cursor: pointer;">
                    Download
                </button>
            `;
            
            resultsGrid.appendChild(resultCard);
        }
        
        function showResults() {
            document.getElementById('resultsSection').style.display = 'block';
        }
        
        async function processAllFaces() {
            showLoading('Batch processing all faces...');
            // Implementation for batch processing
            hideLoading();
        }
        
        function downloadResults() {
            // Implementation for PSD download
            alert('PSD download feature coming soon!');
        }
        
        function downloadSingle(faceId) {
            const result = processedResults.find(r => r.face_id === faceId);
            if (!result) return;
            
            // Convert base64 to blob and download
            const link = document.createElement('a');
            link.href = 'data:image/png;base64,' + result.processed_face;
            link.download = `${faceId}_processed.png`;
            link.click();
        }
        
        function showLoading(text) {
            document.getElementById('loadingText').textContent = text;
            document.getElementById('loadingOverlay').style.display = 'block';
        }
        
        function hideLoading() {
            document.getElementById('loadingOverlay').style.display = 'none';
        }
        
        // Drag and drop functionality
        document.getElementById('mainUpload').addEventListener('dragover', (e) => {
            e.preventDefault();
            e.currentTarget.style.background = 'rgba(74, 222, 128, 0.2)';
        });
        
        document.getElementById('mainUpload').addEventListener('dragleave', (e) => {
            e.currentTarget.style.background = 'rgba(255, 255, 255, 0.15)';
        });
        
        document.getElementById('mainUpload').addEventListener('drop', (e) => {
            e.preventDefault();
            e.currentTarget.style.background = 'rgba(255, 255, 255, 0.15)';
            
            if (e.dataTransfer.files.length > 0) {
                sourceFile = e.dataTransfer.files[0];
                detectFaces();
            }
        });
    </script>
</body>
</html>
"""

# FastAPI routes
@web_app.get("/", response_class=HTMLResponse)
async def home():
    """Serve the advanced multi-face web interface"""
    return ADVANCED_HTML_TEMPLATE

@web_app.post("/detect-faces")
async def detect_faces_endpoint(file: UploadFile = File(...)):
    """Endpoint for face detection and ethnicity classification"""
    file_bytes = await file.read()
    
    # Call Modal function for face detection
    detect_fn = modal.Function.lookup("playalter-platform-v2", "detect_faces")
    result = detect_fn.remote(
        file_bytes=file_bytes,
        file_type=file.content_type
    )
    
    return JSONResponse(content=result)

@web_app.post("/process-face")
async def process_face_endpoint(
    source_file: UploadFile = File(...),
    face_id: str = Form(...),
    bbox: str = Form(...),
    ethnicity: str = Form(...),
    operation: str = Form(...),
    target_file: Optional[UploadFile] = File(None)
):
    """Endpoint for processing individual faces"""
    source_bytes = await source_file.read()
    bbox_data = json.loads(bbox)
    ethnicity_data = json.loads(ethnicity)
    
    target_bytes = None
    if target_file:
        target_bytes = await target_file.read()
    
    # Call Modal function for face processing
    process_fn = modal.Function.lookup("playalter-platform-v2", "process_individual_face")
    result = process_fn.remote(
        source_bytes=source_bytes,
        face_id=face_id,
        bbox=bbox_data,
        ethnicity_data=ethnicity_data,
        operation=operation,
        target_bytes=target_bytes
    )
    
    return JSONResponse(content=result)

@web_app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy", 
        "platform": "PLAYALTER v2.0",
        "version": "2.0.0",
        "features": [
            "Multi-face detection (up to 30 faces)",
            "Ethnicity-aware processing",
            "Advanced privacy masks",
            "Batch operations",
            "Video processing"
        ]
    }

# Modal ASGI app
@app.function(image=image)
@modal.asgi_app()
def fastapi_app():
    """Serve the advanced FastAPI app through Modal"""
    return web_app

if __name__ == "__main__":
    print("PLAYALTER v2.0 Platform ready for deployment!")
    print("Features: Multi-face detection, Ethnicity-aware processing, Advanced UI")
    print("Deploy with: modal deploy main_app_v2.py")